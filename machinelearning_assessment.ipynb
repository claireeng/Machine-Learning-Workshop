{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Programming Workshop Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Dataset:** Mobile dataset, derived from Shopee National Data Science Challenge 2019\n",
    "- **Goal:** Code out a neural network in Keras to classify product titles into the corresponding phone brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./files/shopee_mobile_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Load Label Names from JSON File</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./files/mobile_profile_train.json') as f:\n",
    "    mobile_profiles = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [pair[0] for pair in sorted(mobile_profiles['Brand'].items(), key=lambda x: x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "['google', 'htc', 'apple', 'wiko', 'polytron', 'gionee', 'leagoo', 'brandcode', 'luna', 'acer', 'sharp', 'blackview', 'prince', 'lg', 'spc', 'coolpad', 'smartfren', 'infinix', 'blaupunkt', 'lava', 'aldo', 'huawei', 'advan', 'leeco', 'nexcom', 'zyrex', 'axioo', 'elephone', 'himax', 'hp', 'nokia', 'nuu mobile', 'icherry', 'xiaomi', 'pixcom', 'mito', 'huang mi', 'maxtron', 'sony', 'indosat', 'philips', 'lenovo', 'alcatel', 'samsung', 'zyo', 'doogee', 'vivo', 'evercoss', 'strawberry', 'ifone', 'fujitsu', 'blackberry', 'asus', 'oneplus', 'honor', 'oppo']\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(class_names)\n",
    "print(num_classes)\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['title', 'Brand']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>Brand</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>itemid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2346660</th>\n",
       "      <td>apple iphone 4s back glass spare part original...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2816338</th>\n",
       "      <td>iphone 4s 64gb white</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847602</th>\n",
       "      <td>samsung sm b310e piton dual sim</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116949</th>\n",
       "      <td>samsung caramel gt e1272 dual sim 32 mb putih</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794648</th>\n",
       "      <td>garskin sony experia z z1 z2 ultra</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title  Brand\n",
       "itemid                                                           \n",
       "2346660  apple iphone 4s back glass spare part original...    2.0\n",
       "2816338                               iphone 4s 64gb white    2.0\n",
       "2847602                    samsung sm b310e piton dual sim   43.0\n",
       "3116949      samsung caramel gt e1272 dual sim 32 mb putih   43.0\n",
       "3794648                 garskin sony experia z z1 z2 ultra   38.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['title']\n",
    "Y = data['Brand']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Process Text</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = K.preprocessing.text.Tokenizer(num_words=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {k: v+2 for k,v in tokenizer.word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index[\"<PAD>\"] = 0    # Used to fill sentences to make Sequence Lengths the same\n",
    "word_index[\"<START>\"] = 1  # To show the start of a sequence\n",
    "word_index[\"UNK\"] = 2      # Used to fill in the gap for unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_data = data['title'].apply(lambda x: [1] + [word_index.get(xi, 2) for xi in x.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_data = K.preprocessing.sequence.pad_sequences(int_data, value=0, padding='post', maxlen=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1  56   6 ...   0   0   0]\n",
      " [  1   6 243 ...   0   0   0]\n",
      " [  1   3 203 ...   0   0   0]\n",
      " ...\n",
      " [  1  22 494 ...   0   0   0]\n",
      " [  1  72  43 ...   0   0   0]\n",
      " [  1  11 197 ...   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(padded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1   56    6  243  251  127 4531 2438   16  904  139    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(padded_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Split Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155038, 30)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.2\n",
    "split_idx = int(split_ratio*len(padded_data))\n",
    "\n",
    "X_train = padded_data[split_idx:]\n",
    "Y_train = Y[split_idx:]\n",
    "\n",
    "X_val = padded_data[:split_idx]\n",
    "Y_val = Y[:split_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Build Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model = K.Sequential([\n",
    "    K.layers.Embedding(len(word_index), 8),\n",
    "    K.layers.GRU(4, return_sequences=False),\n",
    "    K.layers.Dense(32, activation='relu'),\n",
    "    K.layers.Dense(16, activation='relu'),\n",
    "    K.layers.Dense(num_classes, activation='softmax'),   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "gru_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002AD98F9FF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002AD98F9FF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1938/1938 [==============================] - 48s 25ms/step - loss: 2.5575 - accuracy: 0.2152\n",
      "Epoch 2/5\n",
      "1938/1938 [==============================] - 46s 24ms/step - loss: 1.8831 - accuracy: 0.3915\n",
      "Epoch 3/5\n",
      "1938/1938 [==============================] - 49s 25ms/step - loss: 0.2379 - accuracy: 0.9424\n",
      "Epoch 4/5\n",
      "1938/1938 [==============================] - 47s 24ms/step - loss: 0.1120 - accuracy: 0.9763\n",
      "Epoch 5/5\n",
      "1938/1938 [==============================] - 45s 23ms/step - loss: 0.0712 - accuracy: 0.9849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ad9a02d8c8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_model.fit(X_train, Y_train, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluate Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002ADA21CB3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002ADA21CB3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "969/969 [==============================] - 5s 5ms/step - loss: 0.0848 - accuracy: 0.9822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08483380079269409, 0.9821653366088867]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_model.evaluate(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['google',\n",
       " 'htc',\n",
       " 'apple',\n",
       " 'wiko',\n",
       " 'polytron',\n",
       " 'gionee',\n",
       " 'leagoo',\n",
       " 'brandcode',\n",
       " 'luna',\n",
       " 'acer',\n",
       " 'sharp',\n",
       " 'blackview',\n",
       " 'prince',\n",
       " 'lg',\n",
       " 'spc',\n",
       " 'coolpad',\n",
       " 'smartfren',\n",
       " 'infinix',\n",
       " 'blaupunkt',\n",
       " 'lava',\n",
       " 'aldo',\n",
       " 'huawei',\n",
       " 'advan',\n",
       " 'leeco',\n",
       " 'nexcom',\n",
       " 'zyrex',\n",
       " 'axioo',\n",
       " 'elephone',\n",
       " 'himax',\n",
       " 'hp',\n",
       " 'nokia',\n",
       " 'nuu mobile',\n",
       " 'icherry',\n",
       " 'xiaomi',\n",
       " 'pixcom',\n",
       " 'mito',\n",
       " 'huang mi',\n",
       " 'maxtron',\n",
       " 'sony',\n",
       " 'indosat',\n",
       " 'philips',\n",
       " 'lenovo',\n",
       " 'alcatel',\n",
       " 'samsung',\n",
       " 'zyo',\n",
       " 'doogee',\n",
       " 'vivo',\n",
       " 'evercoss',\n",
       " 'strawberry',\n",
       " 'ifone',\n",
       " 'fujitsu',\n",
       " 'blackberry',\n",
       " 'asus',\n",
       " 'oneplus',\n",
       " 'honor',\n",
       " 'oppo']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002ADA43DC678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002ADA43DC678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "preds = gru_model.predict(X_val)\n",
    "class_preds = np.argmax(preds,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_text = data['title'].iloc[:split_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple iphone 4s back glass spare part original replacement putih\n",
      "True Value: apple | Predicted: apple\n",
      "\n",
      "iphone 4s 64gb white\n",
      "True Value: apple | Predicted: apple\n",
      "\n",
      "samsung sm b310e piton dual sim\n",
      "True Value: samsung | Predicted: samsung\n",
      "\n",
      "samsung caramel gt e1272 dual sim 32 mb putih\n",
      "True Value: samsung | Predicted: samsung\n",
      "\n",
      "garskin sony experia z z1 z2 ultra\n",
      "True Value: sony | Predicted: sony\n",
      "\n",
      "lcd xiaomi redmi 4+touchscreen\n",
      "True Value: xiaomi | Predicted: xiaomi\n",
      "\n",
      "samsung caramel gt e1272 dual sim 32mb black\n",
      "True Value: samsung | Predicted: samsung\n",
      "\n",
      "iphone 4g 8gb\n",
      "True Value: apple | Predicted: apple\n",
      "\n",
      "blackberry torch 1 9800 gsm garansi distributor 2 tahun white\n",
      "True Value: blackberry | Predicted: blackberry\n",
      "\n",
      "samsung keystone 3 sm b109e\n",
      "True Value: samsung | Predicted: samsung\n",
      "\n",
      "samsung galaxy j5 j 500g 8 gb hitam\n",
      "True Value: samsung | Predicted: samsung\n",
      "\n",
      "samsung galaxy j1 mini sm j105 8gb white\n",
      "True Value: samsung | Predicted: samsung\n",
      "\n",
      "iphone 5 white 16gb fullset mulus\n",
      "True Value: apple | Predicted: apple\n",
      "\n",
      "lenovo a 6000 se 1 16 white\n",
      "True Value: lenovo | Predicted: lenovo\n",
      "\n",
      "samsung galaxy j1\n",
      "True Value: samsung | Predicted: samsung\n",
      "\n",
      "keypad blackberry 9360 hitam\n",
      "True Value: blackberry | Predicted: blackberry\n",
      "\n",
      "xiaomi redmi 3pro 3s\n",
      "True Value: xiaomi | Predicted: xiaomi\n",
      "\n",
      "iphone 6s 64gb\n",
      "True Value: apple | Predicted: apple\n",
      "\n",
      "iphone 5 garansi 1 thn platinum\n",
      "True Value: apple | Predicted: apple\n",
      "\n",
      "iphone 5s 32gb\n",
      "True Value: apple | Predicted: apple\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(val_text.iloc[i])\n",
    "    print('True Value: {} | Predicted: {}'.format(class_names[int(Y_val.iloc[i])], class_names[class_preds[i]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Predictor Function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(text):\n",
    "    int_data = [1] + [word_index.get(xi, 2) for xi in text.lower().split()]\n",
    "    padded_data = K.preprocessing.sequence.pad_sequences([int_data], value=0, padding='post', maxlen=30)\n",
    "    pred = gru_model.predict(padded_data)\n",
    "    idx = np.argmax(pred)\n",
    "    class_pred = class_names[idx]\n",
    "    return class_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['google', 'htc', 'apple', 'wiko', 'polytron', 'gionee', 'leagoo', 'brandcode', 'luna', 'acer', 'sharp', 'blackview', 'prince', 'lg', 'spc', 'coolpad', 'smartfren', 'infinix', 'blaupunkt', 'lava', 'aldo', 'huawei', 'advan', 'leeco', 'nexcom', 'zyrex', 'axioo', 'elephone', 'himax', 'hp', 'nokia', 'nuu mobile', 'icherry', 'xiaomi', 'pixcom', 'mito', 'huang mi', 'maxtron', 'sony', 'indosat', 'philips', 'lenovo', 'alcatel', 'samsung', 'zyo', 'doogee', 'vivo', 'evercoss', 'strawberry', 'ifone', 'fujitsu', 'blackberry', 'asus', 'oneplus', 'honor', 'oppo']\n"
     ]
    }
   ],
   "source": [
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'philips'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Philips EP2220/10 LatteGo 3000 Series Classic Milk Frother Black\"\n",
    "predictor(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
